# Model Context Protocol - MCP

Слово авторам:
  * MAR 10, 2025 [Why MCP Won](https://www.latent.space/p/why-mcp-won) - Learnings from Anthropic's extraordinarily successful Launch and Workshop
  * APR 03, 2025 [Latent Space: The AI Engineer Podcast](https://www.latent.space/p/mcp) - When we first wrote Why MCP Won, we had no idea how quickly it was about to win. In the past 4 weeks, OpenAI and now Google have now announced the MCP support, effectively confirming our prediction that MCP was the presumptive winner of the agent standard wars. MCP has now overtaken OpenAPI.


Model Context Protocol (MCP) — это новый подход к взаимодействию с большими языковыми моделями (LLM), позволяющий им работать с внешними данными, помнить больше информации и быть более “контекстно осведомлёнными”. Если совсем просто, MCP — это способ расширить память и контекст LLM, подключив её к внешним источникам данных, которые можно динамически подгружать и управлять ими.

## Зачем нужен MCP?

Большие языковые модели, такие как GPT, Claude или Gemini, работают внутри ограниченного контекстного окна - например, могут “удерживать в голове” ограниченное количество токенов, что мало для серьезных бизнес-задач. Ещё хуже - модель ничего не помнит между сессиями: каждый раз вы начинаете с чистого листа.

Как в этом помогает MCP:
  * позволяет хранить “память” модели вне самой модели - в виде баз данных, файлов или специальных векторов;
  * даёт доступ к внешним источникам: базам знаний, API, корпоративным данным;
  * предоставляет гибкую систему управления контекстом - что, когда и зачем “показать” модели.

## В чём отличие MCP от старых подходов?

**Контекст — это не просто текст, а среда выполнения**

Раньше, когда мы хотели добавить знание в GPT (например, в ChatGPT через плагины), мы просто:
  * делали плагин;
  * по запросу дергали API или базу;
  * вставляли результат в prompt.

Это **line-by-line механика** - модель ничего не знает о данных заранее, контекст передаётся целиком каждый раз. 

MCP вместо этого **создаёт абстрактный слой**, где знания и доступ к ним организованы в формате “регистров” и “каналов”, как в реальной ОС. Он сам управляет:
  * что нужно загрузить;
  * когда это сделать;
  * как представить модели.

**Главное отличие: управление контекстом становится программируемым, модульным и переносимым.**

Представим, что вы строите AI, который помогает CEO компании, и этот ИИ должен учитывать:
  * расписание CEO,
  * документы, над которыми он работает,
  * недавние email’ы и задачи.

Если вы реализуете это через плагины — вы просто делаете десяток ручных запросов и склеиваете результат.

С MCP — вы создаёте системный уровень, где:
  * каждая сущность (календарь, документы, задачи) — это регистровый модуль, с интерфейсом load, query, hydrate;
  * модель не знает всего сразу — MCP сам решает, что ей “вспомнить” в нужный момент;
  * вы можете “приостановить”, “перезапустить” или “перенести” эту память как состояние AI.

## MCP — попытка создать стандартизированный, масштабируемый и управляемый слой памяти и знаний для LLM

Он предлагает:
  * Регистры - концепции, которые хранят определённый контекст (например, “рабочий день пользователя”);
  * Протоколы загрузки/выгрузки - что подгружать в текущий prompt;
  * Слои интерпретации - MCP может сам адаптировать данные под формат, удобный модели (chunking, summarization, embedding и т.д.);
  * Модульность и переносимость - как у Docker или Linux, вы можете “подключить” MCP к другой модели.

## Как подключить MCP к своему AI

Метод настройки примерно одинаковый везде, например в Cursor AI это делается в файле ```~/.cursor/mcp.json``` и буквально прописывается в несколько строк (работает в Cursor и MCP-use):

```JSON
"mcp.servers": {
  "atlassian": {
    "command": "npx",
    "args": ["-y", "mcp-remote", "https://mcp.atlassian.com/v1/sse"]
  },
  "playwright": {
    "command": "npx",
    "args": ["@playwright/mcp@latest"],
    "env": {
      "DISPLAY": ":1"
    }
  }
}
```

## Как собрать свой

Есть [классный пример](https://modelcontextprotocol.io/quickstart/server#claude-for-desktop-integration-issues) как собрать свой MCP с простой задачей (и позже развить до сложной). Если хочется сделать MCP [как доступный HTTP](https://shivdeepak.com/posts/lets-write-a-remote-mcp-server/) сервис.

## Коллекция MCP

  1. [Apple MCP tools](https://github.com/supermemoryai/apple-mcp) - позволяет связывать команды в цепочку, создавая рабочий процесс. Например: «Пожалуйста, прочитай заметку о людях, с которыми я познакомился на конференции, найди их контакты и email’ы, и отправь им сообщение с благодарностью за уделённое время».
  2. [Context7 MCP](https://github.com/upstash/context7) - подтягивает актуальную, версионную документацию и примеры кода напрямую из источника — и вставляет их прямо в prompt. Context7 добавляет свежие примеры и документацию прямо в контекст LLM. Больше не нужно переключать вкладки, сталкиваться с выдуманными API или устаревшими фрагментами кода.
  3. [Interactive Feedback MCP](https://github.com/noopstudios/interactive-feedback-mcp) - простой MCP-сервер, позволяющий реализовать сценарий с участием человека в цикле разработки с AI (human-in-the-loop), например, в инструментах вроде Cursor. Сервер позволяет запускать команды, просматривать их вывод и напрямую оставлять текстовую обратную связь для модели. Также совместим с Cline и Windsurf.
  4. [Sequential Thinking MCP Server](https://github.com/modelcontextprotocol/servers/tree/main/src/sequentialthinking) - реализация, предоставляющая инструмент для динамического и рефлексивного решения задач через структурированный мыслительный процесс.
  5. [Asana](https://developers.asana.com/docs/using-asanas-mcp-server) MCP Server - позволяет AI-ассистентам и другим приложениям получать доступ к Asana Work Graph за пределами платформы Asana. Этот сервер предоставляет способ взаимодействия с рабочим пространством Asana через различные AI-платформы и инструменты, поддерживающие MCP.
  6. [Slack MCP Server](https://github.com/korotovsky/slack-mcp-server/tree/master) - для чтения сообщений, поиска по каналам и тредам, доступа к личным и групповым чатам, с поддержкой “умной истории” (по дате или количеству), встроенной информацией о пользователях и кэшированием. Он работает в двух режимах - **Stealth (без установки бота и разрешений)** и OAuth (с безопасным доступом по токену), совместим с корпоративными Slack-средами, поддерживает Stdio/SSE транспорты и прокси, а отправка сообщений отключена по умолчанию для безопасности.
  7. [Atlassian Remote MCP Server](https://support.atlassian.com/rovo/docs/getting-started-with-the-atlassian-remote-mcp-server/) - это облачный мост между вашим Atlassian Cloud-сайтом и совместимыми внешними инструментами. После настройки он позволяет этим инструментам взаимодействовать с данными Jira и Confluence в режиме реального времени. Работа сервера основана на защищённой авторизации OAuth 2.1, которая гарантирует, что все действия соблюдают существующие права доступа пользователя.
  8. [MCP-Use](https://github.com/mcp-use/mcp-use?tab=readme-ov-file) - это способ с открытым исходным кодом подключить любую LLM к любому MCP-серверу и создавать собственные MCP-агенты с доступом к инструментам - без использования проприетарных решений или клиентских приложений.

* [Невероятно длинный список MCP](https://github.com/modelcontextprotocol/servers/tree/main) под все нужды (вероятно)
* [Model Context Protocol](https://github.com/modelcontextprotocol) - The Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools. Whether you're building an AI-powered IDE, enhancing a chat interface, or creating custom AI workflows, MCP provides a standardized way to connect LLMs with the context they need.
